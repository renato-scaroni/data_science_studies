{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "41_min",
     "81_min"
    ]
   },
   "source": [
    "# Do the types of crimes committed in Chicago depend on location and time?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "7_min"
    ]
   },
   "source": [
    "## Preparing the data\n",
    "\n",
    "Let's import the libraries we will be using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import chi2_contingency\n",
    "import pingouin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first read in the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/chicago_crime_data.csv', dtype={'ID': object, 'beat_num': object})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, there are *many* categories in the `Primary Type` and `Location Description` columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Primary Type\"].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Location Description\"].drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So let's group them into wider categories to make our analysis easier. For that, we will use these two dictionaries that we prepared beforehand:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_Locations = {'AIRPORT TERMINAL UPPER LEVEL - NON-SECURE AREA': 'Airport & Related',\n",
    " 'AIRPORT EXTERIOR - SECURE AREA': 'Airport & Related',\n",
    " 'AIRCRAFT': 'Airport & Related',\n",
    " 'AIRPORT TERMINAL LOWER LEVEL - NON-SECURE AREA': 'Airport & Related',\n",
    " 'AIRPORT BUILDING NON-TERMINAL - NON-SECURE AREA': 'Airport & Related',\n",
    " 'AIRPORT TERMINAL UPPER LEVEL - SECURE AREA': 'Airport & Related',\n",
    " 'AIRPORT PARKING LOT': 'Airport & Related',\n",
    " 'AIRPORT BUILDING NON-TERMINAL - SECURE AREA': 'Airport & Related',\n",
    " 'AIRPORT TERMINAL LOWER LEVEL - SECURE AREA': 'Airport & Related',\n",
    " 'AIRPORT TERMINAL MEZZANINE - NON-SECURE AREA': 'Airport & Related',\n",
    " 'AIRPORT TRANSPORTATION SYSTEM (ATS)': 'Airport & Related',\n",
    " 'AIRPORT VENDING ESTABLISHMENT': 'Airport & Related',\n",
    " 'AIRPORT/AIRCRAFT': 'Airport & Related',\n",
    " 'AIRPORT EXTERIOR - NON-SECURE AREA': 'Airport & Related',\n",
    " 'HOSPITAL BUILDING/GROUNDS': 'Hospitals & Related',\n",
    " 'MEDICAL/DENTAL OFFICE': 'Hospitals & Related',\n",
    " 'NURSING HOME': 'Hospitals & Related',\n",
    " 'ANIMAL HOSPITAL': 'Hospitals & Related',\n",
    " 'NURSING HOME/RETIREMENT HOME': 'Hospitals & Related',\n",
    " 'STAIRWELL': 'Residential & Related',\n",
    " 'DRIVEWAY - RESIDENTIAL': 'Residential & Related',\n",
    " 'RESIDENCE-GARAGE': 'Residential & Related',\n",
    " 'HOUSE': 'Residential & Related',\n",
    " 'PORCH': 'Residential & Related',\n",
    " 'CHA HALLWAY': 'Residential & Related',\n",
    " 'CHA APARTMENT': 'Residential & Related',\n",
    " 'BASEMENT': 'Residential & Related',\n",
    " 'CHA PARKING LOT/GROUNDS': 'Residential & Related',\n",
    " 'RESIDENCE PORCH/HALLWAY': 'Residential & Related',\n",
    " 'APARTMENT': 'Residential & Related',\n",
    " 'GARAGE': 'Residential & Related',\n",
    " 'RESIDENCE': 'Residential & Related',\n",
    " 'ROOMING HOUSE': 'Residential & Related',\n",
    " 'CHA HALLWAY/STAIRWELL/ELEVATOR': 'Residential & Related',\n",
    " 'HOTEL/MOTEL': 'Residential & Related',\n",
    " 'CHA PARKING LOT': 'Residential & Related',\n",
    " 'RESIDENTIAL YARD (FRONT/BACK)': 'Residential & Related',\n",
    " 'COLLEGE/UNIVERSITY RESIDENCE HALL': 'Colleges & Related',\n",
    " 'SCHOOL, PUBLIC, GROUNDS': 'Colleges & Related',\n",
    " 'SCHOOL, PRIVATE, GROUNDS': 'Colleges & Related',\n",
    " 'SCHOOL YARD': 'Colleges & Related',\n",
    " 'DAY CARE CENTER': 'Colleges & Related',\n",
    " 'COLLEGE/UNIVERSITY GROUNDS': 'Colleges & Related',\n",
    " 'SCHOOL, PUBLIC, BUILDING': 'Colleges & Related',\n",
    " 'SCHOOL, PRIVATE, BUILDING': 'Colleges & Related',\n",
    " 'JAIL / LOCK-UP FACILITY': 'Goverment Buildings & Related',\n",
    " 'GOVERNMENT BUILDING/PROPERTY': 'Goverment Buildings & Related',\n",
    " 'POLICE FACILITY/VEH PARKING LOT': 'Goverment Buildings & Related',\n",
    " 'FIRE STATION': 'Goverment Buildings & Related',\n",
    " 'PARK PROPERTY': 'Goverment Buildings & Related',\n",
    " 'FEDERAL BUILDING': 'Goverment Buildings & Related',\n",
    " 'FOREST PRESERVE': 'Goverment Buildings & Related',\n",
    " 'LIBRARY': 'Goverment Buildings & Related',\n",
    " 'TAVERN/LIQUOR STORE': 'Liquor Stores & Related',\n",
    " 'CLUB': 'Liquor Stores & Related',\n",
    " 'TAVERN': 'Liquor Stores & Related',\n",
    " 'POOL ROOM': 'Liquor Stores & Related',\n",
    " 'BAR OR TAVERN': 'Liquor Stores & Related',\n",
    " 'ATHLETIC CLUB': 'Stores & Related',\n",
    " 'BARBERSHOP': 'Stores & Related',\n",
    " 'CONVENIENCE STORE': 'Stores & Related',\n",
    " 'SMALL RETAIL STORE': 'Stores & Related',\n",
    " 'RESTAURANT': 'Stores & Related',\n",
    " 'DRUG STORE': 'Stores & Related',\n",
    " 'FACTORY/MANUFACTURING BUILDING': 'Stores & Related',\n",
    " 'MOVIE HOUSE/THEATER': 'Stores & Related',\n",
    " 'RETAIL STORE': 'Stores & Related',\n",
    " 'PARKING LOT': 'Stores & Related',\n",
    " 'DEPARTMENT STORE': 'Stores & Related',\n",
    " 'GAS STATION': 'Stores & Related',\n",
    " 'VESTIBULE': 'Stores & Related',\n",
    " 'CAR WASH': 'Stores & Related',\n",
    " 'CLEANING STORE': 'Stores & Related',\n",
    " 'GAS STATION DRIVE/PROP.': 'Stores & Related',\n",
    " 'NEWSSTAND': 'Stores & Related',\n",
    " 'COIN OPERATED MACHINE': 'Stores & Related',\n",
    " 'APPLIANCE STORE': 'Stores & Related',\n",
    " 'COMMERCIAL / BUSINESS OFFICE': 'Stores & Related',\n",
    " 'BOWLING ALLEY': 'Stores & Related',\n",
    " 'GROCERY FOOD STORE': 'Stores & Related',\n",
    " 'GANGWAY': 'Vehicles & Related',\n",
    " 'VEHICLE - DELIVERY TRUCK': 'Vehicles & Related',\n",
    " 'BOAT/WATERCRAFT': 'Vehicles & Related',\n",
    " 'TAXICAB': 'Vehicles & Related',\n",
    " 'VEHICLE-COMMERCIAL': 'Vehicles & Related',\n",
    " 'OTHER COMMERCIAL TRANSPORTATION': 'Vehicles & Related',\n",
    " 'AUTO': 'Vehicles & Related',\n",
    " 'AUTO / BOAT / RV DEALERSHIP': 'Vehicles & Related',\n",
    " 'VEHICLE - OTHER RIDE SERVICE': 'Vehicles & Related',\n",
    " 'VEHICLE NON-COMMERCIAL': 'Vehicles & Related',\n",
    " 'VEHICLE - OTHER RIDE SHARE SERVICE (E.G., UBER, LYFT)': 'Vehicles & Related',\n",
    " 'CTA BUS': 'Public Transport & Related',\n",
    " 'CTA TRAIN': 'Public Transport & Related',\n",
    " 'OTHER RAILROAD PROP / TRAIN DEPOT': 'Public Transport & Related',\n",
    " 'CTA BUS STOP': 'Public Transport & Related',\n",
    " 'CTA PROPERTY': 'Public Transport & Related',\n",
    " 'CTA STATION': 'Public Transport & Related',\n",
    " 'CTA PLATFORM': 'Public Transport & Related',\n",
    " 'CTA \"L\" PLATFORM': 'Public Transport & Related',\n",
    " 'CTA GARAGE / OTHER PROPERTY': 'Public Transport & Related',\n",
    " 'CTA TRACKS - RIGHT OF WAY': 'Public Transport & Related',\n",
    " 'ALLEY': 'Street & Related',\n",
    " 'BRIDGE': 'Street & Related',\n",
    " 'CEMETARY': 'Street & Related',\n",
    " 'CHURCH': 'Street & Related',\n",
    " 'SIDEWALK': 'Street & Related',\n",
    " 'HALLWAY': 'Street & Related',\n",
    " 'ABANDONED BUILDING': 'Street & Related',\n",
    " 'SPORTS ARENA/STADIUM': 'Street & Related',\n",
    " 'CONSTRUCTION SITE': 'Street & Related',\n",
    " 'DRIVEWAY': 'Street & Related',\n",
    " 'YARD': 'Street & Related',\n",
    " 'VACANT LOT': 'Street & Related',\n",
    " 'STREET': 'Street & Related',\n",
    " 'LAKEFRONT/WATERFRONT/RIVERBANK': 'Street & Related',\n",
    " 'CHURCH/SYNAGOGUE/PLACE OF WORSHIP': 'Street & Related',\n",
    " 'HIGHWAY/EXPRESSWAY': 'Street & Related',\n",
    " 'VACANT LOT/LAND': 'Street & Related',\n",
    " 'PARKING LOT/GARAGE(NON.RESID.)': 'Street & Related',\n",
    " 'CREDIT UNION': 'Bank & Related',\n",
    " 'CURRENCY EXCHANGE': 'Bank & Related',\n",
    " 'PAWN SHOP': 'Bank & Related',\n",
    " 'RIVER BANK': 'Bank & Related',\n",
    " 'SAVINGS AND LOAN': 'Bank & Related',\n",
    " 'WAREHOUSE': 'Bank & Related',\n",
    " 'ATM (AUTOMATIC TELLER MACHINE)': 'Bank & Related',\n",
    " 'BANK': 'Bank & Related',\n",
    " 'OTHER': 'Other Locations'}\n",
    "\n",
    "dict_Offenses = {'CRIMINAL TRESPASS': 'Theft Related',\n",
    " 'MOTOR VEHICLE THEFT': 'Theft Related',\n",
    " 'BURGLARY': 'Theft Related',\n",
    " 'ROBBERY': 'Theft Related',\n",
    " 'THEFT': 'Theft Related',\n",
    " 'ARSON': 'Property Damage',\n",
    " 'CRIMINAL DAMAGE': 'Property Damage',\n",
    " 'HOMICIDE': 'Violence & Related',\n",
    " 'KIDNAPPING': 'Violence & Related',\n",
    " 'ASSAULT': 'Violence & Related',\n",
    " 'BATTERY': 'Violence & Related',\n",
    " 'OFFENSE INVOLVING CHILDREN': 'Sexual Offenses & Related',\n",
    " 'SEX OFFENSE': 'Sexual Offenses & Related',\n",
    " 'HUMAN TRAFFICKING': 'Sexual Offenses & Related',\n",
    " 'PROSTITUTION': 'Sexual Offenses & Related',\n",
    " 'CRIM SEXUAL ASSAULT': 'Sexual Offenses & Related',\n",
    " 'PUBLIC INDECENCY': 'Sexual Offenses & Related',\n",
    " 'OBSCENITY': 'Sexual Offenses & Related',\n",
    " 'STALKING': 'Sexual Offenses & Related',\n",
    " 'INTIMIDATION': 'Dangerous practices',\n",
    " 'INTERFERENCE WITH PUBLIC OFFICER': 'Dangerous practices',\n",
    " 'WEAPONS VIOLATION': 'Dangerous practices',\n",
    " 'CONCEALED CARRY LICENSE VIOLATION': 'Dangerous practices',\n",
    " 'DECEPTIVE PRACTICE': 'Dangerous practices',\n",
    " 'LIQUOR LAW VIOLATION': 'Substances & Related',\n",
    " 'GAMBLING': 'Substances & Related',\n",
    " 'OTHER NARCOTIC VIOLATION': 'Substances & Related',\n",
    " 'NARCOTICS': 'Substances & Related',\n",
    " 'OTHER OFFENSE': 'Other Offenses',\n",
    " 'PUBLIC PEACE VIOLATIONNON-CRIMINAL': 'Other Offenses',\n",
    " 'NON-CRIMINAL (SUBJECT SPECIFIED)': 'Other Offenses'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it's simply a matter of creating the new columns and replacing the values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Offenses_cat\"]=df[\"Primary Type\"].replace(dict_Offenses)\n",
    "df[\"Location_cat\"]=df[\"Location Description\"].replace(dict_Locations)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "7_min"
    ]
   },
   "source": [
    "## `pandas`'s `crosstab()` function\n",
    "\n",
    "To make contingency tables in `pandas`, we use the [**`crosstab()`**](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.crosstab.html) function. You simply specify which Series will be the rows of the table (`index` argument) and which Series will be the columns (`columns` argument), like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_contingency_table = pd.crosstab(index=df[\"Offenses_cat\"], columns=df[\"Location_cat\"])\n",
    "my_contingency_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how the `concat()` function outputs *counts* by default. We can make it show *percentages* with the `normalize` argument. You can normalize in one of two ways:\n",
    "\n",
    "1. taking the sum of each column and dividing the respective column values by that sum (`normalize=\"columns\"`); or\n",
    "2. taking the sum of each row and dividing all the respective row values by that sum (`normalize=\"index\"`)\n",
    "\n",
    "This diagram illustrates the difference:\n",
    "\n",
    "![](data/images/crosstab_normalize_explanation.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "3_min"
    ]
   },
   "source": [
    "### Example 1\n",
    "\n",
    "Produce a contingency table in which the values are the percentage of offenses in a particular location that were of a specific crime type."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer.** Shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(index=df[\"Offenses_cat\"], columns=df[\"Location_cat\"], normalize=\"columns\")*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we multiplied the entire table by 100 to make the percentages easier to read (since they are given as decimals rather than percentages by default).\n",
    "\n",
    "In this table, you can see that of all the offenses that happened in airports, 20.24% were of the type \"Dangerous practices\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "7_min"
    ]
   },
   "source": [
    "### Exercise 1\n",
    "\n",
    "Produce a contingency table in which the values are the percentage of offenses of a particular type that occurred in a particular location. Looking only at offenses of type \"Property Damage\", what is the most common location where this type of offense occurred, and what is its relative frequency?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "ans_st"
    ]
   },
   "source": [
    "**Answer.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "5_min"
    ]
   },
   "source": [
    "One good way of visualizing contingency tables is with heat maps. To make heat maps like the ones we saw during lecture, we can use the [`sns.heatmap()`](https://seaborn.pydata.org/generated/seaborn.heatmap.html) function. Keeping the defaults, this is what we get:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(my_contingency_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make it more legible, let's change the color palette. There are [many](https://medium.com/@morganjonesartist/color-guide-to-seaborn-palettes-da849406d44f) available, but we will stick to the `Reds` palette:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(my_contingency_table, cmap=\"Reds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can add a title by tweaking the code slightly (to see all the options available, check the [documentation](https://seaborn.pydata.org/generated/seaborn.heatmap.html)):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.heatmap(my_contingency_table, cmap=\"Reds\")\n",
    "ax.set_title(\"Primary type vs. Location description (counts)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "7_min"
    ]
   },
   "source": [
    "### Exercise 2\n",
    "\n",
    "Make a heat map of the normalized contingency table you created in Exercise 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "ans_st"
    ]
   },
   "source": [
    "**Answer.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "2_min"
    ]
   },
   "source": [
    "## Executing hypothesis tests\n",
    "\n",
    "In the last few cases, we have introduced the intuition behind the hypothesis testing framework. We learned that we can use the $t$ - test to compare the mean of a sample with another value (to determine if there is a statistically significant difference between them). We also saw how we can extend this logic with the $\\chi^2$-test to decide if two categorical variables are independent of each other or not. Here, we will show you how to conduct both types of tests using the `pingouin` and `scipy` Python libraries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "7_min"
    ]
   },
   "source": [
    "### The $t$ - test with `pingouin`\n",
    "\n",
    "The `pingouin` library makes it very easy to run $t$ - tests with the [**`ttest()`**](https://pingouin-stats.org/generated/pingouin.ttest.html) function. You simply need to pass the sample data and the value to compare with as arguments. For instance, let's say that we wanted to compare the mean of dataset `A` (below) with the value 56. Are the two numbers statistically different? The code we would use would be the following (note that we imported `pinguoin` at the start of this notebook):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing dataset A, which is a Series of integers\n",
    "A = pd.read_csv(\"data/A.csv\")\n",
    "\n",
    "# Here, A[\"A\"] is the Series, our sample (its mean is 39.6, and the sample size is 244)\n",
    "# And 56 is the value to compare with\n",
    "pingouin.ttest(A[\"A\"], 56)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see from the output, since the $p$ - value is essentially zero, we can reject the null hypothesis. The output also tells us that the test was two-sided (see the `tail` column).\n",
    "\n",
    "In the case that you have two samples whose means you want to compare (a two-sample $t$ - test), the syntax is almost identical, with the only difference being that instead of providing a number as the comparison point, you provide the second dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing dataset B, which is another Series of integers\n",
    "B = pd.read_csv(\"data/B.csv\")\n",
    "\n",
    "# Here, B[\"B\"] is the second Series (its mean is 37.15, and the sample size is 215)\n",
    "pingouin.ttest(A[\"A\"],  B[\"B\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output shows that there is not enough evidence to reject the null hypothesis at a significance level of 0.05. In other words, the means of samples `A` and `B` are statistically indistinguishable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "4_min"
    ]
   },
   "source": [
    "### Exercise 3\n",
    "\n",
    "Conduct a two-sample $t$ test between the `A` and `C` datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing dataset C, which is another Series of integers\n",
    "C = pd.read_csv(\"data/C.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "ans_st"
    ]
   },
   "source": [
    "**Answer.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "5_min"
    ]
   },
   "source": [
    "### The $\\chi^2$ - test with `scipy`\n",
    "\n",
    "Running chi-squared tests is quite easy in Python using the `scipy` library. If you have a look at the top of this notebook, you will see that we imported the [**`chi2_contingency()`**](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.chi2_contingency.html) function from this library using this code:\n",
    "\n",
    "~~~python\n",
    "from scipy.stats import chi2_contingency\n",
    "~~~\n",
    "\n",
    "The only thing we have to do now is call the `chi2_contingency()` function and pass the relevant contingency table (not normalized) as the argument:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chi2_contingency(my_contingency_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The $p$ - value is the second number in the output. Therefore, to only show the $p$-value, we can index the output like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chi2_contingency(my_contingency_table)[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "12_min"
    ]
   },
   "source": [
    "### Exercise 4\n",
    "\n",
    "This is a subset of the dataset in which we only included the offenses that are violent crimes with locations in residential areas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_df = df[\n",
    "    (df['Location_cat'] == 'Residential & Related') &\n",
    "    (df['Offenses_cat'] == 'Violence & Related')\n",
    "]\n",
    "subset_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a contingency table of `Location Description` versus `Primary Type` using this smaller dataset, plot it as a heat map, and report the $p$ - value of a $\\chi^2$ test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "ans_st"
    ]
   },
   "source": [
    "**Answer.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "5_min"
    ]
   },
   "source": [
    "## Discretizing time to make it categorical\n",
    "\n",
    "We can make use of the date and time methods that `pandas` provides to discretize time. Let's first convert the `Date` column to the native `pandas` `datetime` data type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"date_reformatted\"] = pd.to_datetime(df[\"Date\"]) # This line might take several seconds to run\n",
    "df[\"date_reformatted\"].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can access the day of the week of each record using the `dt` accessor and the `dayofweek` attribute (for an exhaustive list of attributes, see the [docs](https://pandas.pydata.org/docs/reference/series.html#datetimelike-properties)). Monday is indexed as day `0`, and Sunday is `6`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"day_of_week\"] = df[\"date_reformatted\"].dt.dayofweek\n",
    "df[\"day_of_week\"].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can create our contingency table as usual:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(df['Offenses_cat'], df['day_of_week'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "10_min"
    ]
   },
   "source": [
    "### Exercise 5\n",
    "\n",
    "We suspect that throughout the course of a typical day, the distribution of crime locations may shift materially. We ask you to:\n",
    "\n",
    "1. Extract the time of the day from the `date_reformatted` column we created in the previous section (**Hint:** For this, use the `dt` accessor and the `hour` attribute)\n",
    "2. Make a contingency table\n",
    "3. Plot the contingency table as a heatmap\n",
    "4. Conduct a $\\chi^2$-test and report the $p$-value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "ans_st"
    ]
   },
   "source": [
    "**Answer.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attribution\n",
    "\n",
    "\"Crimes - 2001 to Present\", March 5, 2021, Chicago Police Department, dataset licensed under the City of Chicago [Terms of Use](https://www.chicago.gov/city/en/narr/foia/data_disclaimer.html), https://data.cityofchicago.org/Public-Safety/Crimes-2001-to-Present/ijzp-q8t2"
   ]
  }
 ],
 "metadata": {
  "c1_recart": "6.7.0-57c20131aabc1dc2a8c675852d80a7da"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
